{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chapter 3 Deepter Look at Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test git\n"
     ]
    }
   ],
   "source": [
    "print('test git')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('second test git')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    0/20 Hypothesis: tensor([33.2170, 37.4436, 38.2034, 41.7334, 27.7426]), Cost: 18568.300781\n",
      "Epoch    1/20 Hypothesis: tensor([ 86.4250, 101.3973, 101.2173, 110.3540,  76.5235]), Cost: 5823.723633\n",
      "Epoch    2/20 Hypothesis: tensor([116.2139, 137.2029, 136.4963, 148.7720, 103.8345]), Cost: 1828.973877\n",
      "Epoch    3/20 Hypothesis: tensor([132.8913, 157.2494, 156.2476, 170.2808, 119.1253]), Cost: 576.830017\n",
      "Epoch    4/20 Hypothesis: tensor([142.2279, 168.4729, 167.3056, 182.3226, 127.6863]), Cost: 184.347626\n",
      "Epoch    5/20 Hypothesis: tensor([147.4548, 174.7568, 173.4964, 189.0643, 132.4797]), Cost: 61.323799\n",
      "Epoch    6/20 Hypothesis: tensor([150.3808, 178.2752, 176.9623, 192.8387, 135.1637]), Cost: 22.760431\n",
      "Epoch    7/20 Hypothesis: tensor([152.0186, 180.2452, 178.9026, 194.9517, 136.6667]), Cost: 10.671152\n",
      "Epoch    8/20 Hypothesis: tensor([152.9351, 181.3484, 179.9888, 196.1346, 137.5085]), Cost: 6.880103\n",
      "Epoch    9/20 Hypothesis: tensor([153.4479, 181.9663, 180.5968, 196.7968, 137.9801]), Cost: 5.690053\n",
      "Epoch   10/20 Hypothesis: tensor([153.7347, 182.3125, 180.9371, 197.1674, 138.2445]), Cost: 5.315299\n",
      "Epoch   11/20 Hypothesis: tensor([153.8948, 182.5066, 181.1275, 197.3749, 138.3929]), Cost: 5.196104\n",
      "Epoch   12/20 Hypothesis: tensor([153.9841, 182.6155, 181.2340, 197.4909, 138.4763]), Cost: 5.156971\n",
      "Epoch   13/20 Hypothesis: tensor([154.0338, 182.6767, 181.2935, 197.5558, 138.5233]), Cost: 5.143002\n",
      "Epoch   14/20 Hypothesis: tensor([154.0612, 182.7112, 181.3267, 197.5920, 138.5500]), Cost: 5.136889\n",
      "Epoch   15/20 Hypothesis: tensor([154.0762, 182.7308, 181.3452, 197.6122, 138.5652]), Cost: 5.133224\n",
      "Epoch   16/20 Hypothesis: tensor([154.0842, 182.7420, 181.3555, 197.6234, 138.5741]), Cost: 5.130344\n",
      "Epoch   17/20 Hypothesis: tensor([154.0883, 182.7486, 181.3611, 197.6296, 138.5794]), Cost: 5.127706\n",
      "Epoch   18/20 Hypothesis: tensor([154.0903, 182.7525, 181.3641, 197.6330, 138.5827]), Cost: 5.125158\n",
      "Epoch   19/20 Hypothesis: tensor([154.0910, 182.7549, 181.3657, 197.6347, 138.5849]), Cost: 5.122607\n",
      "Epoch   20/20 Hypothesis: tensor([154.0911, 182.7565, 181.3665, 197.6357, 138.5865]), Cost: 5.120065\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import Module\n",
    "\n",
    "# torch.manual_seed(1)\n",
    "# 데이터\n",
    "x_train = torch.FloatTensor([[73,80,75],\n",
    "[93,88,93],\n",
    "[89,91,90],\n",
    "[96,98,100],\n",
    "[73,66,70]])\n",
    "y_train = torch.FloatTensor([[152],[185],[180],[196],[142]])\n",
    "\n",
    "model = Module.MultivariateLinearRegressionModel()\n",
    "optimizer=torch.optim.SGD(model.parameters(),lr=1e-5)\n",
    "\n",
    "nb_epochs=20\n",
    "for epoch in range(nb_epochs+1):\n",
    "    Hypothesis=model(x_train)\n",
    "    cost=F.mse_loss(Hypothesis,y_train)\n",
    "    optimizer.zero_grad()\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "    print('Epoch {:4d}/{} Hypothesis: {}, Cost: {:.6f}'.format(\n",
    "        epoch,nb_epochs,Hypothesis.squeeze().detach(),\n",
    "        cost.item()\n",
    "    ))\n",
    "\n",
    "\n",
    "\n",
    "# import torch\n",
    "# import torch.optim as optim\n",
    "\n",
    "# #데이터\n",
    "# x_train = torch.FloatTensor([[1],[2],[3]])\n",
    "# y_train= torch.FloatTensor([[1],[2],[3]])\n",
    "# # 모델 초기화\n",
    "# W = torch.zeros(1, requires_grad = True)\n",
    "# # Optimizer 설정\n",
    "# optimizer = optim.SGD([W], lr=0.15)\n",
    "\n",
    "# nb_epochs = 10\n",
    "# for epoch in range(nb_epochs + 1):\n",
    "#     # H(x) 계산\n",
    "#     hypothesis = x_train * W\n",
    "\n",
    "#     # cost 계산\n",
    "#     cost = torch.mean((hypothesis - y_train) ** 2)\n",
    "\n",
    "#     print('Epoch {:4d}/{} W: {:.3f} Cost: {:.6f}'.format(\n",
    "#         epoch, nb_epochs, W.item(), cost.item()\n",
    "#     ))\n",
    "\n",
    "\n",
    "#     optimizer.zero_grad()\n",
    "#     cost.backward()\n",
    "#     optimizer.step()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chapter 4 Multivariable Linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    0/20 hypothesis: tensor([0., 0., 0., 0., 0.]) Cost: 29661.800781\n",
      "Epoch    1/20 hypothesis: tensor([67.2578, 80.8397, 79.6523, 86.7394, 61.6605]) Cost: 9298.520508\n",
      "Epoch    2/20 hypothesis: tensor([104.9128, 126.0990, 124.2466, 135.3015,  96.1821]) Cost: 2915.712891\n",
      "Epoch    3/20 hypothesis: tensor([125.9942, 151.4381, 149.2133, 162.4896, 115.5097]) Cost: 915.040527\n",
      "Epoch    4/20 hypothesis: tensor([137.7968, 165.6247, 163.1911, 177.7112, 126.3307]) Cost: 287.936005\n",
      "Epoch    5/20 hypothesis: tensor([144.4044, 173.5674, 171.0168, 186.2332, 132.3891]) Cost: 91.371010\n",
      "Epoch    6/20 hypothesis: tensor([148.1035, 178.0144, 175.3980, 191.0042, 135.7812]) Cost: 29.758139\n",
      "Epoch    7/20 hypothesis: tensor([150.1744, 180.5042, 177.8508, 193.6753, 137.6805]) Cost: 10.445305\n",
      "Epoch    8/20 hypothesis: tensor([151.3336, 181.8983, 179.2240, 195.1707, 138.7440]) Cost: 4.391228\n",
      "Epoch    9/20 hypothesis: tensor([151.9824, 182.6789, 179.9928, 196.0079, 139.3396]) Cost: 2.493135\n",
      "Epoch   10/20 hypothesis: tensor([152.3454, 183.1161, 180.4231, 196.4765, 139.6732]) Cost: 1.897688\n",
      "Epoch   11/20 hypothesis: tensor([152.5485, 183.3610, 180.6640, 196.7389, 139.8602]) Cost: 1.710541\n",
      "Epoch   12/20 hypothesis: tensor([152.6620, 183.4982, 180.7988, 196.8857, 139.9651]) Cost: 1.651412\n",
      "Epoch   13/20 hypothesis: tensor([152.7253, 183.5752, 180.8742, 196.9678, 140.0240]) Cost: 1.632387\n",
      "Epoch   14/20 hypothesis: tensor([152.7606, 183.6184, 180.9164, 197.0138, 140.0571]) Cost: 1.625923\n",
      "Epoch   15/20 hypothesis: tensor([152.7802, 183.6427, 180.9399, 197.0395, 140.0759]) Cost: 1.623412\n",
      "Epoch   16/20 hypothesis: tensor([152.7909, 183.6565, 180.9530, 197.0538, 140.0865]) Cost: 1.622141\n",
      "Epoch   17/20 hypothesis: tensor([152.7968, 183.6643, 180.9603, 197.0618, 140.0927]) Cost: 1.621253\n",
      "Epoch   18/20 hypothesis: tensor([152.7999, 183.6688, 180.9644, 197.0662, 140.0963]) Cost: 1.620500\n",
      "Epoch   19/20 hypothesis: tensor([152.8014, 183.6715, 180.9666, 197.0686, 140.0985]) Cost: 1.619770\n",
      "Epoch   20/20 hypothesis: tensor([152.8020, 183.6731, 180.9677, 197.0699, 140.1000]) Cost: 1.619033\n"
     ]
    }
   ],
   "source": [
    "x_train = torch.FloatTensor([[73,80,75],\n",
    "[93,88,93],\n",
    "[89,91,90],\n",
    "[96,98,100],\n",
    "[73,66,70]])\n",
    "y_train = torch.FloatTensor([[152],[185],[180],[196],[142]])\n",
    "\n",
    "#모델 초기화\n",
    "W = torch.zeros((3, 1), requires_grad = True)\n",
    "b = torch.zeros(1, requires_grad = True)\n",
    "\n",
    "\n",
    "optimizer = optim.SGD([W, b], lr=1e-5)\n",
    "nb_epochs = 20\n",
    "for epoch in range(nb_epochs + 1):\n",
    "    # H(x) 계산\n",
    "    hypothesis = x_train.matmul(W)+b\n",
    "    # cost 계산\n",
    "    cost=torch.mean((hypothesis - y_train) ** 2)\n",
    "    optimizer.zero_grad()\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    print('Epoch {:4d}/{} hypothesis: {} Cost: {:.6f}'.format(\n",
    "    epoch, nb_epochs, hypothesis.squeeze().detach(),\n",
    "    cost.item()\n",
    "\n",
    "))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chapter 4-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    0/20 Hypothesis: tensor([-40.0693, -45.2010, -46.0207, -51.1201, -32.8219]), Cost: 46519.898438\n",
      "Epoch    1/20 Hypothesis: tensor([44.1627, 56.0395, 53.7334, 57.5095, 44.3990]), Cost: 14581.706055\n",
      "Epoch    2/20 Hypothesis: tensor([ 91.3212, 112.7202, 109.5820, 118.3273,  87.6320]), Cost: 4570.780762\n",
      "Epoch    3/20 Hypothesis: tensor([117.7235, 144.4536, 140.8496, 152.3769, 111.8366]), Cost: 1432.888306\n",
      "Epoch    4/20 Hypothesis: tensor([132.5053, 162.2200, 158.3552, 171.4401, 125.3878]), Cost: 449.324310\n",
      "Epoch    5/20 Hypothesis: tensor([140.7811, 172.1667, 168.1560, 182.1129, 132.9746]), Cost: 141.029800\n",
      "Epoch    6/20 Hypothesis: tensor([145.4145, 177.7355, 173.6430, 188.0881, 137.2221]), Cost: 44.395958\n",
      "Epoch    7/20 Hypothesis: tensor([148.0086, 180.8532, 176.7151, 191.4335, 139.6001]), Cost: 14.106120\n",
      "Epoch    8/20 Hypothesis: tensor([149.4610, 182.5986, 178.4350, 193.3065, 140.9314]), Cost: 4.611867\n",
      "Epoch    9/20 Hypothesis: tensor([150.2742, 183.5758, 179.3980, 194.3551, 141.6767]), Cost: 1.635889\n",
      "Epoch   10/20 Hypothesis: tensor([150.7295, 184.1229, 179.9371, 194.9422, 142.0939]), Cost: 0.703070\n",
      "Epoch   11/20 Hypothesis: tensor([150.9844, 184.4291, 180.2390, 195.2709, 142.3274]), Cost: 0.410630\n",
      "Epoch   12/20 Hypothesis: tensor([151.1272, 184.6005, 180.4079, 195.4550, 142.4581]), Cost: 0.318935\n",
      "Epoch   13/20 Hypothesis: tensor([151.2072, 184.6965, 180.5026, 195.5580, 142.5313]), Cost: 0.290166\n",
      "Epoch   14/20 Hypothesis: tensor([151.2521, 184.7502, 180.5556, 195.6157, 142.5722]), Cost: 0.281112\n",
      "Epoch   15/20 Hypothesis: tensor([151.2772, 184.7802, 180.5853, 195.6481, 142.5950]), Cost: 0.278246\n",
      "Epoch   16/20 Hypothesis: tensor([151.2913, 184.7970, 180.6019, 195.6662, 142.6078]), Cost: 0.277319\n",
      "Epoch   17/20 Hypothesis: tensor([151.2993, 184.8063, 180.6113, 195.6763, 142.6148]), Cost: 0.276989\n",
      "Epoch   18/20 Hypothesis: tensor([151.3038, 184.8115, 180.6165, 195.6820, 142.6188]), Cost: 0.276855\n",
      "Epoch   19/20 Hypothesis: tensor([151.3064, 184.8144, 180.6194, 195.6852, 142.6209]), Cost: 0.276782\n",
      "Epoch   20/20 Hypothesis: tensor([151.3078, 184.8160, 180.6211, 195.6870, 142.6221]), Cost: 0.276730\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "x_train = torch.FloatTensor([[73,80,75],\n",
    "[93,88,93],\n",
    "[89,91,90],\n",
    "[96,98,100],\n",
    "[73,66,70]])\n",
    "y_train = torch.FloatTensor([[152],[185],[180],[196],[142]])\n",
    "class MultivariateLinearRegressionModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(3, 1) # 다중 선형 회귀이므로 input_dim=3, output_dim=1.\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear(x)\n",
    "model = MultivariateLinearRegressionModel()\n",
    "optimizer=torch.optim.SGD(model.parameters(),lr=1e-5)\n",
    "\n",
    "nb_epochs=20\n",
    "for epoch in range(nb_epochs+1):\n",
    "    Hypothesis=model(x_train)\n",
    "    cost=F.mse_loss(Hypothesis,y_train)\n",
    "    optimizer.zero_grad()\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "    print('Epoch {:4d}/{} Hypothesis: {}, Cost: {:.6f}'.format(\n",
    "        epoch,nb_epochs,Hypothesis.squeeze().detach(),\n",
    "        cost.item()\n",
    "    ))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chapter 4-2 Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    0/20 Batch 1/3 Cost: 40548.742188\n",
      "Epoch    0/20 Batch 2/3 Cost: 7291.496094\n",
      "Epoch    0/20 Batch 3/3 Cost: 1811.472900\n",
      "Epoch    1/20 Batch 1/3 Cost: 1189.893066\n",
      "Epoch    1/20 Batch 2/3 Cost: 401.466431\n",
      "Epoch    1/20 Batch 3/3 Cost: 98.862206\n",
      "Epoch    2/20 Batch 1/3 Cost: 59.924492\n",
      "Epoch    2/20 Batch 2/3 Cost: 5.558980\n",
      "Epoch    2/20 Batch 3/3 Cost: 0.005015\n",
      "Epoch    3/20 Batch 1/3 Cost: 7.238761\n",
      "Epoch    3/20 Batch 2/3 Cost: 0.579780\n",
      "Epoch    3/20 Batch 3/3 Cost: 9.432348\n",
      "Epoch    4/20 Batch 1/3 Cost: 2.596262\n",
      "Epoch    4/20 Batch 2/3 Cost: 6.112612\n",
      "Epoch    4/20 Batch 3/3 Cost: 0.173577\n",
      "Epoch    5/20 Batch 1/3 Cost: 0.585829\n",
      "Epoch    5/20 Batch 2/3 Cost: 3.764513\n",
      "Epoch    5/20 Batch 3/3 Cost: 4.496191\n",
      "Epoch    6/20 Batch 1/3 Cost: 1.750849\n",
      "Epoch    6/20 Batch 2/3 Cost: 2.692057\n",
      "Epoch    6/20 Batch 3/3 Cost: 4.092385\n",
      "Epoch    7/20 Batch 1/3 Cost: 0.873102\n",
      "Epoch    7/20 Batch 2/3 Cost: 3.545603\n",
      "Epoch    7/20 Batch 3/3 Cost: 4.466603\n",
      "Epoch    8/20 Batch 1/3 Cost: 2.943422\n",
      "Epoch    8/20 Batch 2/3 Cost: 2.787016\n",
      "Epoch    8/20 Batch 3/3 Cost: 3.619492\n",
      "Epoch    9/20 Batch 1/3 Cost: 3.126629\n",
      "Epoch    9/20 Batch 2/3 Cost: 3.285140\n",
      "Epoch    9/20 Batch 3/3 Cost: 3.671584\n",
      "Epoch   10/20 Batch 1/3 Cost: 4.018391\n",
      "Epoch   10/20 Batch 2/3 Cost: 3.578519\n",
      "Epoch   10/20 Batch 3/3 Cost: 4.788294\n",
      "Epoch   11/20 Batch 1/3 Cost: 2.840858\n",
      "Epoch   11/20 Batch 2/3 Cost: 1.529948\n",
      "Epoch   11/20 Batch 3/3 Cost: 5.260645\n",
      "Epoch   12/20 Batch 1/3 Cost: 2.605290\n",
      "Epoch   12/20 Batch 2/3 Cost: 2.249615\n",
      "Epoch   12/20 Batch 3/3 Cost: 4.657380\n",
      "Epoch   13/20 Batch 1/3 Cost: 2.926507\n",
      "Epoch   13/20 Batch 2/3 Cost: 1.515777\n",
      "Epoch   13/20 Batch 3/3 Cost: 4.302320\n",
      "Epoch   14/20 Batch 1/3 Cost: 0.500335\n",
      "Epoch   14/20 Batch 2/3 Cost: 6.037371\n",
      "Epoch   14/20 Batch 3/3 Cost: 4.123126\n",
      "Epoch   15/20 Batch 1/3 Cost: 1.343143\n",
      "Epoch   15/20 Batch 2/3 Cost: 3.552392\n",
      "Epoch   15/20 Batch 3/3 Cost: 4.573134\n",
      "Epoch   16/20 Batch 1/3 Cost: 3.172205\n",
      "Epoch   16/20 Batch 2/3 Cost: 3.901104\n",
      "Epoch   16/20 Batch 3/3 Cost: 5.279982\n",
      "Epoch   17/20 Batch 1/3 Cost: 2.121088\n",
      "Epoch   17/20 Batch 2/3 Cost: 3.004843\n",
      "Epoch   17/20 Batch 3/3 Cost: 5.418248\n",
      "Epoch   18/20 Batch 1/3 Cost: 2.273925\n",
      "Epoch   18/20 Batch 2/3 Cost: 2.860945\n",
      "Epoch   18/20 Batch 3/3 Cost: 3.722516\n",
      "Epoch   19/20 Batch 1/3 Cost: 3.066788\n",
      "Epoch   19/20 Batch 2/3 Cost: 3.034842\n",
      "Epoch   19/20 Batch 3/3 Cost: 0.832807\n",
      "Epoch   20/20 Batch 1/3 Cost: 2.018387\n",
      "Epoch   20/20 Batch 2/3 Cost: 6.400998\n",
      "Epoch   20/20 Batch 3/3 Cost: 0.817560\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F \n",
    "from torch.utils.data import Dataset \n",
    "from torch.utils.data import DataLoader \n",
    "# Dataset 상속\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        self.x_data = [[73, 80, 75],\n",
    "                        [93, 88, 93],\n",
    "                        [89, 91, 90],\n",
    "                        [96,98,100],\n",
    "                        [73, 66, 70]]\n",
    "        self.y_data = [[152], [185], [180], [196], [142]]\n",
    "\n",
    "# 총 데이터의 개수를 리턴\n",
    "    def __len__(self):\n",
    "        return len(self.x_data)\n",
    "\n",
    "# 인텍스를 입력받아 그에 맵핑되는 입출력 데이터를 파이토치의 Tensor 형태로 리턴\n",
    "    def __getitem__(self, idx):\n",
    "        x = torch.FloatTensor(self.x_data[idx])\n",
    "        y = torch.FloatTensor(self.y_data[idx])\n",
    "        return x, y\n",
    "dataset = CustomDataset()\n",
    "dataloader = DataLoader(dataset, batch_size=2, shuffle=True)\n",
    "model = torch.nn.Linear(3,1)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-5)\n",
    "nb_epochs = 20\n",
    "for epoch in range(nb_epochs + 1):\n",
    "    for batch_idx, samples in enumerate(dataloader):\n",
    "        # print(batch_idx)\n",
    "        # print(samples)\n",
    "        x_train, y_train = samples \n",
    "        # H(x) 계산\n",
    "        prediction = model(x_train)\n",
    "\n",
    "        # cost 계산\n",
    "        cost = F.mse_loss(prediction, y_train)\n",
    "\n",
    "        # cost로 H(x) 계산\n",
    "        optimizer.zero_grad()\n",
    "        cost.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        print('Epoch {:4d}/{} Batch {}/{} Cost: {:.6f}'.format(\n",
    "            epoch, nb_epochs, batch_idx+1, len(dataloader),\n",
    "            cost.item()\n",
    "        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9abbf7dbf133a7e19a7525f81e59961c4c6417802777913fbde59b00fd82043f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
